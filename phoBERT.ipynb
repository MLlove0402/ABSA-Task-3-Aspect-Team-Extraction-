{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"phoBERT.ipynb","provenance":[],"authorship_tag":"ABX9TyPGzGsO4Co6D6X/+9eR3hkZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"tUlbNAPFYdqe","executionInfo":{"status":"ok","timestamp":1602483061060,"user_tz":-420,"elapsed":20944,"user":{"displayName":"THAI NGUYEN QUOC","photoUrl":"","userId":"14553785917059170356"}},"outputId":"b281bb32-abcc-451f-9d31-d56b96654f8e","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PBgR_deQZUMF","executionInfo":{"status":"ok","timestamp":1602483061061,"user_tz":-420,"elapsed":5161,"user":{"displayName":"THAI NGUYEN QUOC","photoUrl":"","userId":"14553785917059170356"}}},"source":["path = \"/content/drive/My Drive/Aspect-based Sentiment Analysis/\""],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"OthBkDhAZVp4","executionInfo":{"status":"ok","timestamp":1602483118096,"user_tz":-420,"elapsed":62004,"user":{"displayName":"THAI NGUYEN QUOC","photoUrl":"","userId":"14553785917059170356"}},"outputId":"e9c4bc83-3eb5-4455-d213-e81352d678f2","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install fairseq\n","!pip3 install vncorenlp\n","!pip3 install transformers\n","!pip install keras-rectified-adam\n","!pip install fastBPE"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting fairseq\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/bf/de299e082e7af010d35162cb9a185dc6c17db71624590f2f379aeb2519ff/fairseq-0.9.0.tar.gz (306kB)\n","\u001b[K     |████████████████████████████████| 307kB 6.0MB/s \n","\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.14.3)\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.29.21)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.18.5)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq) (2019.12.20)\n","Collecting sacrebleu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/c4/8e948f601a4f9609e8b2b58f31966cb13cf17b940b82aa3e767f01c42c52/sacrebleu-1.4.14-py3-none-any.whl (64kB)\n","\u001b[K     |████████████████████████████████| 71kB 6.6MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.6.0+cu101)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq) (4.41.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq) (2.20)\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->fairseq) (0.16.0)\n","Building wheels for collected packages: fairseq\n","  Building wheel for fairseq (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fairseq: filename=fairseq-0.9.0-cp36-cp36m-linux_x86_64.whl size=2046471 sha256=5fa346bfdcaf7315b98a7993c0dcb9c4a29c37c2a89435e2f2e7da0ca1fa0ca8\n","  Stored in directory: /root/.cache/pip/wheels/37/3e/1b/0fa30695dcba41e4b0088067fa40f3328d1e8ee78c22cd4766\n","Successfully built fairseq\n","Installing collected packages: portalocker, sacrebleu, fairseq\n","Successfully installed fairseq-0.9.0 portalocker-2.0.0 sacrebleu-1.4.14\n","Collecting vncorenlp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/c2/96a60cf75421ecc740829fa920c617b3dd7fa6791e17554e7c6f3e7d7fca/vncorenlp-1.0.3.tar.gz (2.6MB)\n","\u001b[K     |████████████████████████████████| 2.7MB 6.0MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vncorenlp) (2.23.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (2020.6.20)\n","Building wheels for collected packages: vncorenlp\n","  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-cp36-none-any.whl size=2645934 sha256=409794934fa75669ba9706822ca73654afedee93219901823f83bb1ad31d629a\n","  Stored in directory: /root/.cache/pip/wheels/09/54/8b/043667de6091d06a381d7745f44174504a9a4a56ecc9380c54\n","Successfully built vncorenlp\n","Installing collected packages: vncorenlp\n","Successfully installed vncorenlp-1.0.3\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 5.7MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers==0.8.1.rc2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 20.5MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Collecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 54.1MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 55.7MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=061bb1b81fcc78a31cca40a9897e730c4f554ba7b53783a4980bd22e99f0866f\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.3.1\n","Collecting keras-rectified-adam\n","  Downloading https://files.pythonhosted.org/packages/21/79/9521f66b92186702cb58a214c1b923b416266381cd824e15a1733f6a5b06/keras-rectified-adam-0.17.0.tar.gz\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-rectified-adam) (1.18.5)\n","Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-rectified-adam) (2.4.3)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (3.13)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (1.4.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-rectified-adam) (2.10.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras->keras-rectified-adam) (1.15.0)\n","Building wheels for collected packages: keras-rectified-adam\n","  Building wheel for keras-rectified-adam (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-rectified-adam: filename=keras_rectified_adam-0.17.0-cp36-none-any.whl size=14783 sha256=7b205be0d5a01f6dc88253a2854808e44f8e9be6679dedb2d7fbf7e9d747f3e3\n","  Stored in directory: /root/.cache/pip/wheels/7b/01/27/3a934e1a5644f5b93c720422a6ef97034ea78a21ba71cfb549\n","Successfully built keras-rectified-adam\n","Installing collected packages: keras-rectified-adam\n","Successfully installed keras-rectified-adam-0.17.0\n","Collecting fastBPE\n","  Downloading https://files.pythonhosted.org/packages/e1/37/f97181428a5d151501b90b2cebedf97c81b034ace753606a3cda5ad4e6e2/fastBPE-0.1.0.tar.gz\n","Building wheels for collected packages: fastBPE\n","  Building wheel for fastBPE (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fastBPE: filename=fastBPE-0.1.0-cp36-cp36m-linux_x86_64.whl size=481513 sha256=76a059d2bf569028a431a0f655f740be006d363e1d037ce63957a00c063dbd94\n","  Stored in directory: /root/.cache/pip/wheels/f3/0c/9c/fc62058b4d473a5602bcd3d3edfece796f123875379ea82d79\n","Successfully built fastBPE\n","Installing collected packages: fastBPE\n","Successfully installed fastBPE-0.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S4nQTLEgyndZ","executionInfo":{"status":"ok","timestamp":1602483120459,"user_tz":-420,"elapsed":64163,"user":{"displayName":"THAI NGUYEN QUOC","photoUrl":"","userId":"14553785917059170356"}}},"source":["import pandas as pd, numpy as np\n","import tensorflow as tf\n","import tensorflow.keras.backend as K\n","from sklearn.model_selection import StratifiedKFold\n","from transformers import *\n","import tokenizers"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"efm_WLimZWBx","executionInfo":{"status":"ok","timestamp":1602483149187,"user_tz":-420,"elapsed":92753,"user":{"displayName":"THAI NGUYEN QUOC","photoUrl":"","userId":"14553785917059170356"}},"outputId":"60964690-2796-4269-880c-2a6989b897d3","colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["!wget https://public.vinai.io/PhoBERT_base_transformers.tar.gz\n","!tar -xzvf PhoBERT_base_transformers.tar.gz"],"execution_count":5,"outputs":[{"output_type":"stream","text":["--2020-10-12 06:12:01--  https://public.vinai.io/PhoBERT_base_transformers.tar.gz\n","Resolving public.vinai.io (public.vinai.io)... 54.192.86.43, 54.192.86.32, 54.192.86.19, ...\n","Connecting to public.vinai.io (public.vinai.io)|54.192.86.43|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 322405979 (307M) [application/x-tar]\n","Saving to: ‘PhoBERT_base_transformers.tar.gz’\n","\n","PhoBERT_base_transf 100%[===================>] 307.47M  12.9MB/s    in 21s     \n","\n","2020-10-12 06:12:23 (14.7 MB/s) - ‘PhoBERT_base_transformers.tar.gz’ saved [322405979/322405979]\n","\n","PhoBERT_base_transformers/\n","PhoBERT_base_transformers/config.json\n","PhoBERT_base_transformers/bpe.codes\n","PhoBERT_base_transformers/model.bin\n","PhoBERT_base_transformers/dict.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Y9FJqyck4cOE","executionInfo":{"status":"ok","timestamp":1602483149485,"user_tz":-420,"elapsed":92867,"user":{"displayName":"THAI NGUYEN QUOC","photoUrl":"","userId":"14553785917059170356"}}},"source":["phoBERT = 'PhoBERT_base_transformers'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"ICFPBSMBcY4x","executionInfo":{"status":"ok","timestamp":1602483151148,"user_tz":-420,"elapsed":94368,"user":{"displayName":"THAI NGUYEN QUOC","photoUrl":"","userId":"14553785917059170356"}}},"source":["import pickle\n","import pandas as pd\n","df = pd.read_csv(path+\"VLSP2018/review_train.csv\")\n","df_dev = pd.read_csv(path+'VLSP2018/review_dev.csv')\n","df_test = pd.read_csv(path+'VLSP2018/review_test.csv')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"G59ynozm0Cfn","executionInfo":{"status":"ok","timestamp":1602483152491,"user_tz":-420,"elapsed":95563,"user":{"displayName":"THAI NGUYEN QUOC","photoUrl":"","userId":"14553785917059170356"}}},"source":["data_train = df.review.to_list()\n","label_train = pickle.load(open(path+'VLSP2018/aspect_train.pkl','rb'))\n","data_dev = df_dev.review.tolist()\n","label_dev =  pickle.load(open(path+'VLSP2018/aspect_dev.pkl','rb'))\n","data_test = df_test.review.tolist()\n","label_test = pickle.load(open(path+'VLSP2018/aspect_test.pkl','rb'))"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"W-gmSPcW0D4o","executionInfo":{"status":"ok","timestamp":1602483152500,"user_tz":-420,"elapsed":95211,"user":{"displayName":"THAI NGUYEN QUOC","photoUrl":"","userId":"14553785917059170356"}}},"source":["from fairseq.data.encoders.fastbpe import fastBPE\n","from fairseq.data import Dictionary\n","class BPE():\n","  bpe_codes = 'PhoBERT_base_transformers/bpe.codes'\n","\n","args = BPE()\n","bpe = fastBPE(args)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZEx5Lr822MP8","executionInfo":{"status":"ok","timestamp":1602483152502,"user_tz":-420,"elapsed":94877,"user":{"displayName":"THAI NGUYEN QUOC","photoUrl":"","userId":"14553785917059170356"}}},"source":["vocab = Dictionary()\n","vocab.add_from_file('PhoBERT_base_transformers/dict.txt')"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"QDY4E6Xd2flv","executionInfo":{"status":"ok","timestamp":1602483152504,"user_tz":-420,"elapsed":94672,"user":{"displayName":"THAI NGUYEN QUOC","photoUrl":"","userId":"14553785917059170356"}}},"source":["import numpy as np\n","from tqdm import tqdm\n","max_sequence_length = 256\n","def convert_lines(lines, vocab, bpe):\n","  '''\n","  lines: list các văn bản input\n","  vocab: từ điển dùng để encoding subwords\n","  bpe: \n","  '''\n","  # Khởi tạo ma trận output\n","  outputs = np.zeros((len(lines), max_sequence_length), dtype=np.int32) # --> shape (number_lines, max_seq_len)\n","  mask_token = np.zeros((len(lines), max_sequence_length), dtype=np.int32)\n","  # Index của các token cls (đầu câu), eos (cuối câu), padding (padding token)\n","  cls_id = 0\n","  eos_id = 2\n","  pad_id = 1\n","\n","  for idx, row in tqdm(enumerate(lines), total=len(lines)): \n","    # Mã hóa subwords theo byte pair encoding(bpe)\n","    subwords = bpe.encode('<s> '+ row +' </s>')\n","    input_ids = vocab.encode_line(subwords, append_eos=False, add_if_not_exist=False).long().tolist()\n","    # Truncate input nếu độ dài vượt quá max_seq_len\n","    if len(input_ids) > max_sequence_length: \n","      input_ids = input_ids[:max_sequence_length] \n","      input_ids[-1] = eos_id\n","    else:\n","      # Padding nếu độ dài câu chưa bằng max_seq_len\n","      input_ids = input_ids + [pad_id, ]*(max_sequence_length - len(input_ids))\n","      mask = [0 if i==1 else 1 for i in input_ids]\n","    outputs[idx,:] = np.array(input_ids)\n","    mask_token[idx,:] = np.array(mask)\n","  return outputs, mask_token"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bkhjrf5n2hQS","executionInfo":{"status":"ok","timestamp":1602483155843,"user_tz":-420,"elapsed":97830,"user":{"displayName":"THAI NGUYEN QUOC","photoUrl":"","userId":"14553785917059170356"}},"outputId":"3a45b6dd-66b8-4384-c1d7-64c54532acb9","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["X_train, X_train_mask = convert_lines(data_train, vocab, bpe)\n","X_dev, X_dev_mask = convert_lines(data_dev, vocab, bpe)\n","X_test, X_test_mask = convert_lines(data_test, vocab, bpe)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["100%|██████████| 2961/2961 [00:01<00:00, 1594.26it/s]\n","100%|██████████| 1290/1290 [00:00<00:00, 1742.71it/s]\n","100%|██████████| 500/500 [00:00<00:00, 717.72it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"sGHrsCLN6M8G","executionInfo":{"status":"ok","timestamp":1602483155845,"user_tz":-420,"elapsed":97660,"user":{"displayName":"THAI NGUYEN QUOC","photoUrl":"","userId":"14553785917059170356"}}},"source":["y_train = np.array(label_train)\n","y_dev = np.array(label_dev)\n","y_test = np.array(label_test)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"jJ5pd3e2_YtS","executionInfo":{"status":"ok","timestamp":1602483155846,"user_tz":-420,"elapsed":97468,"user":{"displayName":"THAI NGUYEN QUOC","photoUrl":"","userId":"14553785917059170356"}}},"source":["from tensorflow.keras.layers import Dense, Input, Flatten,SpatialDropout1D,Bidirectional, BatchNormalization\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding, Concatenate, Dropout,GlobalMaxPool1D,Lambda,MaxPool1D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Bidirectional,LSTM,GRU\n","from tensorflow.keras.optimizers import Adam"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"rmRtbcjLp-S2","executionInfo":{"status":"ok","timestamp":1602483155848,"user_tz":-420,"elapsed":96784,"user":{"displayName":"THAI NGUYEN QUOC","photoUrl":"","userId":"14553785917059170356"}}},"source":["def f1(y_true, y_pred):\n","    y_true = K.flatten(y_true)\n","    y_pred = K.flatten(y_pred)\n","    return 2 * (K.sum(y_true * y_pred)+ K.epsilon()) / (K.sum(y_true) + K.sum(y_pred) + K.epsilon())"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"E6Vbybk_o3cb","executionInfo":{"status":"ok","timestamp":1602483342733,"user_tz":-420,"elapsed":4005,"user":{"displayName":"THAI NGUYEN QUOC","photoUrl":"","userId":"14553785917059170356"}},"outputId":"c69526da-c7d4-4037-f506-4d72e5760edd","colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["config = RobertaConfig.from_pretrained(\n","  phoBERT+'/config.json',\n","  output_hidden_states=True,\n","  num_labels=12\n","  )\n","model_bert = TFRobertaModel.from_pretrained(phoBERT+'/model.bin', config=config, from_pt=True)\n","\n","input_ids = Input(shape=(256,), name='input_token', dtype='int32')\n","input_mask = Input(shape=(256,), name='mask_token', dtype='int32')\n","\n","pretrain = model_bert(input_ids, attention_mask=input_mask)[0]\n","cls_token = pretrain[:,0,:]\n","dropout_layer = Dropout(0.2)(cls_token)\n","\n","dense_layer = Dense(768, activation='relu')(dropout_layer)\n","dense_layer = Dense(512, activation='relu')(dense_layer)\n","dense_layer = Dense(256, activation='relu')(dense_layer)\n","preds = Dense(12, activation='sigmoid')(dense_layer)\n","\n","model = Model([input_ids,input_mask], preds)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"CLXREun0siPN","executionInfo":{"status":"ok","timestamp":1602483353881,"user_tz":-420,"elapsed":880,"user":{"displayName":"THAI NGUYEN QUOC","photoUrl":"","userId":"14553785917059170356"}}},"source":["def calculating_class_weights(y_true):\n","    from sklearn.utils.class_weight import compute_class_weight\n","    number_dim = np.shape(y_true)[1]\n","    weights = np.empty([number_dim, 2])\n","    for i in range(number_dim):\n","        weights[i] = compute_class_weight('balanced', [0.,1.], y_true[:, i])\n","    return weights\n","cw = calculating_class_weights(y_train)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"NgJ5U5ii1Btn","executionInfo":{"status":"ok","timestamp":1602483354889,"user_tz":-420,"elapsed":563,"user":{"displayName":"THAI NGUYEN QUOC","photoUrl":"","userId":"14553785917059170356"}}},"source":["LR = 3e-5\n","EPOCHS = 10\n","BATCH_SIZE = 16"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"OI_dL3vosXRx","executionInfo":{"status":"ok","timestamp":1602483355937,"user_tz":-420,"elapsed":952,"user":{"displayName":"THAI NGUYEN QUOC","photoUrl":"","userId":"14553785917059170356"}}},"source":["model.compile(loss='binary_crossentropy',\n","              optimizer=Adam(learning_rate=LR),\n","              metrics=[f1])"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"3TwqXSfDrzPl","executionInfo":{"status":"ok","timestamp":1602483358357,"user_tz":-420,"elapsed":853,"user":{"displayName":"THAI NGUYEN QUOC","photoUrl":"","userId":"14553785917059170356"}}},"source":["from tensorflow.keras.callbacks import ModelCheckpoint \n","checkpoint = ModelCheckpoint(path+'phoBERT_checkpoint', monitor='val_f1', verbose=1, save_best_only=True, mode='max')\n","callbacks_list = [checkpoint]"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZH0FvGDisWRK","executionInfo":{"status":"ok","timestamp":1602487345955,"user_tz":-420,"elapsed":1695738,"user":{"displayName":"THAI NGUYEN QUOC","photoUrl":"","userId":"14553785917059170356"}},"outputId":"b1d9eb8e-c25a-468b-a8b8-4daecf3071e9","colab":{"base_uri":"https://localhost:8080/","height":462}},"source":["model.fit([X_train, X_train_mask], y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose = 1, validation_data=([X_test, X_test_mask], y_test))     "],"execution_count":23,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_2/roberta/pooler/dense/kernel:0', 'tf_roberta_model_2/roberta/pooler/dense/bias:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_2/roberta/pooler/dense/kernel:0', 'tf_roberta_model_2/roberta/pooler/dense/bias:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_2/roberta/pooler/dense/kernel:0', 'tf_roberta_model_2/roberta/pooler/dense/bias:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model_2/roberta/pooler/dense/kernel:0', 'tf_roberta_model_2/roberta/pooler/dense/bias:0'] when minimizing the loss.\n","186/186 [==============================] - 169s 909ms/step - loss: 0.3891 - f1: 0.5286 - val_loss: 0.5014 - val_f1: 0.6073\n","Epoch 2/10\n","186/186 [==============================] - 167s 897ms/step - loss: 0.2923 - f1: 0.6418 - val_loss: 0.4268 - val_f1: 0.6566\n","Epoch 3/10\n","186/186 [==============================] - 167s 896ms/step - loss: 0.2291 - f1: 0.7181 - val_loss: 0.3747 - val_f1: 0.6933\n","Epoch 4/10\n","186/186 [==============================] - 167s 896ms/step - loss: 0.1842 - f1: 0.7743 - val_loss: 0.3732 - val_f1: 0.7320\n","Epoch 5/10\n","186/186 [==============================] - 167s 896ms/step - loss: 0.1557 - f1: 0.8112 - val_loss: 0.3963 - val_f1: 0.7483\n","Epoch 6/10\n","186/186 [==============================] - 167s 898ms/step - loss: 0.1223 - f1: 0.8493 - val_loss: 0.4297 - val_f1: 0.7273\n","Epoch 7/10\n","186/186 [==============================] - 167s 896ms/step - loss: 0.0972 - f1: 0.8795 - val_loss: 0.4868 - val_f1: 0.7543\n","Epoch 8/10\n","186/186 [==============================] - 167s 896ms/step - loss: 0.0772 - f1: 0.9041 - val_loss: 0.4818 - val_f1: 0.7694\n","Epoch 9/10\n","186/186 [==============================] - 166s 895ms/step - loss: 0.0584 - f1: 0.9258 - val_loss: 0.4786 - val_f1: 0.7819\n","Epoch 10/10\n","186/186 [==============================] - 167s 896ms/step - loss: 0.0480 - f1: 0.9379 - val_loss: 0.5383 - val_f1: 0.7775\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fd40dbcde48>"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"fdRvu2CZQcGY","executionInfo":{"status":"ok","timestamp":1602476197874,"user_tz":-420,"elapsed":991662,"user":{"displayName":"THAI NGUYEN QUOC","photoUrl":"","userId":"14553785917059170356"}},"outputId":"68d2bb51-4156-47a7-bcc3-561ec85314f3","colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["model.fit([X_train, X_train_mask], y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose = 1, validation_data=([X_test, X_test_mask], y_test))     "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","186/186 [==============================] - 99s 530ms/step - loss: 0.0580 - f1: 0.9255 - val_loss: 0.5174 - val_f1: 0.7658\n","Epoch 2/10\n","186/186 [==============================] - 98s 529ms/step - loss: 0.0474 - f1: 0.9386 - val_loss: 0.5312 - val_f1: 0.7783\n","Epoch 3/10\n","186/186 [==============================] - 98s 530ms/step - loss: 0.0454 - f1: 0.9429 - val_loss: 0.6108 - val_f1: 0.7782\n","Epoch 4/10\n","186/186 [==============================] - 98s 529ms/step - loss: 0.0330 - f1: 0.9569 - val_loss: 0.5881 - val_f1: 0.7867\n","Epoch 5/10\n","186/186 [==============================] - 98s 529ms/step - loss: 0.0244 - f1: 0.9669 - val_loss: 0.6549 - val_f1: 0.7821\n","Epoch 6/10\n","186/186 [==============================] - 98s 528ms/step - loss: 0.0239 - f1: 0.9693 - val_loss: 0.6737 - val_f1: 0.7889\n","Epoch 7/10\n","186/186 [==============================] - 98s 529ms/step - loss: 0.0262 - f1: 0.9678 - val_loss: 0.6857 - val_f1: 0.7868\n","Epoch 8/10\n","186/186 [==============================] - 98s 528ms/step - loss: 0.0181 - f1: 0.9757 - val_loss: 0.6705 - val_f1: 0.7959\n","Epoch 9/10\n","186/186 [==============================] - 99s 530ms/step - loss: 0.0161 - f1: 0.9779 - val_loss: 0.7683 - val_f1: 0.7807\n","Epoch 10/10\n","186/186 [==============================] - 99s 532ms/step - loss: 0.0213 - f1: 0.9735 - val_loss: 0.7765 - val_f1: 0.7892\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f533873d748>"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"Wx8N0Xhb_DEf"},"source":["\n","EPOCHS = 20\n","BATCH_SIZE = 6\n","ACCUMULATION_STEPS = 5\n","FOLD = 4\n","LR = 0.0001\n","LR_DC_STEP = 80 \n","LR_DC = 0.1\n","CUR_DIR = os.path.dirname(os.getcwd())\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","FOLD = 4\n","CKPT_PATH2 = 'model_ckpt2'\n","\n","if not os.path.exists(CKPT_PATH2):\n","    os.mkdir(CKPT_PATH2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UmRoZ2hWEPiL"},"source":["train_dataset = torch.utils.data.TensorDataset(torch.tensor(X_train,dtype=torch.long), torch.tensor(y_train,dtype=torch.long))\n","valid_dataset = torch.utils.data.TensorDataset(torch.tensor(X_dev,dtype=torch.long), torch.tensor(y_dev,dtype=torch.long))\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Dh9W7517oM3"},"source":["param_optimizer = list(model_bert.named_parameters())\n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]\n","\n","num_train_optimization_steps = int(EPOCHS*len(train_dataset)/BATCH_SIZE/ACCUMULATION_STEPS)\n","optimizer = AdamW(optimizer_grouped_parameters, lr=LR, correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=num_train_optimization_steps)  # scheduler với linear warmup\n","scheduler0 = get_constant_schedule(optimizer)  # scheduler với hằng số\n","# optimizer = optim.Adam(phoBERT_cls.parameters(), LR)\n","criteria = nn.BCEWithLogitsLoss()\n","# scheduler = StepLR(optimizer, step_size = LR_DC_STEP, gamma = LR_DC)\n","avg_loss = 0.\n","avg_accuracy = 0.\n","frozen = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mo9kSQfw9iVN"},"source":["label_dev = np.array(label_dev)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8xvzp2Zp-UqG","outputId":"54dc377d-e198-4aa2-98bd-352fa3ecd79e","colab":{"base_uri":"https://localhost:8080/","height":621}},"source":["frozen = True\n","for epoch in tqdm(range(EPOCHS)):\n","  if epoch > 0 and frozen:\n","      for child in tsfm.children():\n","          for param in child.parameters():\n","              param.requires_grad = True\n","      frozen = False\n","      del scheduler0\n","      torch.cuda.empty_cache()\n","\n","  val_preds = None\n","  avg_loss = 0.\n","  avg_accuracy = 0.\n","\n","  for i,(x_batch, y_batch) in enumerate(train_loader):\n","      model_bert.train()\n","      \n","      y_pred = model_bert(x_batch.cuda(), attention_mask=(x_batch>0).cuda())\n","      loss =  criteria(y_pred.cuda(),y_batch.float().cuda())\n","      loss.backward()\n","      optimizer.step()\n","      if not frozen:\n","          scheduler.step()\n","      else:\n","          scheduler0.step()\n","      optimizer.zero_grad()\n","      avg_loss = loss.item() / len(train_loader)\n","  print('avg_loss: ',avg_loss)\n","  model_bert.eval()\n","  pred_labels, true_labels = [], []\n","  for j,(x_batch_valid, y_batch_valid) in enumerate(valid_loader):\n","    y_pred_valid = model_bert(x_batch_valid.cuda(), attention_mask=(x_batch_valid>0).cuda())\n","    y_pred_valid = y_pred_valid.squeeze().detach().cpu().numpy()\n","    pred_labels.append(y_pred_valid)\n","    true_labels.append(y_batch_valid.squeeze().detach().cpu().numpy())\n","\n","  pred_labels = [item for sublist in pred_labels for item in sublist]\n","  true_labels = [item for sublist in true_labels for item in sublist]\n","  threshold = 0.50\n","  pred_bools = [pl>threshold for pl in pred_labels]\n","  true_bools = [tl==1 for tl in true_labels]\n","  score = f1_score(true_bools, pred_bools, average ='micro')\n","  print(f\"F1 score @0.5 = {score:.4f}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","  0%|          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["avg_loss:  0.000825245129434686\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n","  5%|▌         | 1/20 [01:39<31:37, 99.86s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["F1 score @0.5 = 0.5565\n","avg_loss:  0.0009285634466511036\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 10%|█         | 2/20 [03:19<29:57, 99.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["F1 score @0.5 = 0.4902\n","avg_loss:  0.0007592557292235525\n"],"name":"stdout"},{"output_type":"stream","text":["\n","\n","\n","\n","\n","\n","\n"," 15%|█▌        | 3/20 [04:59<28:17, 99.85s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["F1 score @0.5 = 0.4902\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DsIP3zxpFwNE"},"source":["y_pred = model_bert(x_batch_valid.cuda(), attention_mask=(x_batch_valid>0).cuda())\n","\n","y_pred = y_pred.detach().cpu().numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Aq1fIZvg1gVV","executionInfo":{"status":"ok","timestamp":1601693534199,"user_tz":-420,"elapsed":740,"user":{"displayName":"THAI NGUYEN QUOC","photoUrl":"","userId":"14553785917059170356"}},"outputId":"513a1ca0-b0e7-4032-c083-64b2be441419","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["a = [[1,2,3,4]]\n","b = [[5,5,67,7]]\n","a +=b\n","a = np.array(a)\n","a>5"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[False, False, False, False],\n","       [False, False,  True,  True]])"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"63KOmQZ4zvh9","executionInfo":{"status":"ok","timestamp":1601651197611,"user_tz":-420,"elapsed":1768,"user":{"displayName":"THAI NGUYEN QUOC","photoUrl":"","userId":"14553785917059170356"}},"outputId":"5404c5d6-f542-427c-82d0-4c699fadcaf6","colab":{"base_uri":"https://localhost:8080/","height":230}},"source":["y_pred>0.5"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[False, False, False,  True,  True, False, False, False, False,\n","        False, False, False],\n","       [False, False, False,  True,  True, False, False, False, False,\n","        False, False, False],\n","       [False, False, False,  True,  True, False, False, False, False,\n","        False, False, False],\n","       [False, False, False,  True, False, False, False, False, False,\n","        False, False, False],\n","       [False, False, False,  True, False, False, False, False, False,\n","        False, False, False],\n","       [False, False, False,  True,  True, False, False, False, False,\n","        False, False, False]])"]},"metadata":{"tags":[]},"execution_count":69}]},{"cell_type":"code","metadata":{"id":"c77gOfwC2J3r","executionInfo":{"status":"ok","timestamp":1601651131635,"user_tz":-420,"elapsed":1465,"user":{"displayName":"THAI NGUYEN QUOC","photoUrl":"","userId":"14553785917059170356"}},"outputId":"bf857534-d31b-4fce-9878-bc69b5d77ce7","colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["k"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0],\n","       [1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n","       [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n","       [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0]])"]},"metadata":{"tags":[]},"execution_count":66}]},{"cell_type":"code","metadata":{"id":"ZOpl31Yp2KD2"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k0BcuhhRy__8","executionInfo":{"status":"error","timestamp":1601650896786,"user_tz":-420,"elapsed":1373,"user":{"displayName":"THAI NGUYEN QUOC","photoUrl":"","userId":"14553785917059170356"}},"outputId":"c4d7fef4-6229-40dc-d4b6-87a832457902","colab":{"base_uri":"https://localhost:8080/","height":317}},"source":["f1_score(y_pred>0.5, k, average='samples')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-60-e289d17eff43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'samples'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1097\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m                        \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                        zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1224\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m                                                  \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1226\u001b[0;31m                                                  zero_division=zero_division)\n\u001b[0m\u001b[1;32m   1227\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001b[0;32m-> 1484\u001b[0;31m                                     pos_label)\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1299\u001b[0m                          str(average_options))\n\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1302\u001b[0m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 90\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and multilabel-indicator targets"]}]}]}