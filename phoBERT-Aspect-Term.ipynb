{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"phoBERT.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"tUlbNAPFYdqe","executionInfo":{"status":"ok","timestamp":1603012484624,"user_tz":-420,"elapsed":18791,"user":{"displayName":"Quốc Thái Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC0wF12OCloSJHbsb4W3DURco7tHfZ9TucBmircA=s64","userId":"10260876001198750079"}},"outputId":"f5ff1d73-ca91-4238-8b69-181588cf53ad","colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PBgR_deQZUMF","executionInfo":{"status":"ok","timestamp":1603012484626,"user_tz":-420,"elapsed":3152,"user":{"displayName":"Quốc Thái Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC0wF12OCloSJHbsb4W3DURco7tHfZ9TucBmircA=s64","userId":"10260876001198750079"}}},"source":["path = \"/content/drive/My Drive/Aspect-based Sentiment Analysis/\""],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"OthBkDhAZVp4","executionInfo":{"status":"ok","timestamp":1603012542348,"user_tz":-420,"elapsed":60674,"user":{"displayName":"Quốc Thái Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC0wF12OCloSJHbsb4W3DURco7tHfZ9TucBmircA=s64","userId":"10260876001198750079"}},"outputId":"328d36ea-ebea-4035-f9f1-c99d7ce9b11c","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!pip install fairseq\n","!pip3 install vncorenlp\n","!pip3 install transformers\n","!pip install fastBPE\n","!pip install keras-radam"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting fairseq\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/bf/de299e082e7af010d35162cb9a185dc6c17db71624590f2f379aeb2519ff/fairseq-0.9.0.tar.gz (306kB)\n","\u001b[K     |████████████████████████████████| 307kB 4.5MB/s \n","\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.14.3)\n","Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from fairseq) (0.29.21)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.18.5)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from fairseq) (2019.12.20)\n","Collecting sacrebleu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/c4/8e948f601a4f9609e8b2b58f31966cb13cf17b940b82aa3e767f01c42c52/sacrebleu-1.4.14-py3-none-any.whl (64kB)\n","\u001b[K     |████████████████████████████████| 71kB 8.1MB/s \n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from fairseq) (1.6.0+cu101)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fairseq) (4.41.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->fairseq) (2.20)\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->fairseq) (0.16.0)\n","Building wheels for collected packages: fairseq\n","  Building wheel for fairseq (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fairseq: filename=fairseq-0.9.0-cp36-cp36m-linux_x86_64.whl size=2046454 sha256=6798a0ab6a5ce3d624fe33a09fd913cf82c7f965d21efbe0fac24f47682fcd22\n","  Stored in directory: /root/.cache/pip/wheels/37/3e/1b/0fa30695dcba41e4b0088067fa40f3328d1e8ee78c22cd4766\n","Successfully built fairseq\n","Installing collected packages: portalocker, sacrebleu, fairseq\n","Successfully installed fairseq-0.9.0 portalocker-2.0.0 sacrebleu-1.4.14\n","Collecting vncorenlp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/c2/96a60cf75421ecc740829fa920c617b3dd7fa6791e17554e7c6f3e7d7fca/vncorenlp-1.0.3.tar.gz (2.6MB)\n","\u001b[K     |████████████████████████████████| 2.7MB 4.8MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from vncorenlp) (2.23.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->vncorenlp) (3.0.4)\n","Building wheels for collected packages: vncorenlp\n","  Building wheel for vncorenlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for vncorenlp: filename=vncorenlp-1.0.3-cp36-none-any.whl size=2645934 sha256=8154816022d2f64ab430a55d538b779123dd1ed7f86af3128dafdfaad5c3afa3\n","  Stored in directory: /root/.cache/pip/wheels/09/54/8b/043667de6091d06a381d7745f44174504a9a4a56ecc9380c54\n","Successfully built vncorenlp\n","Installing collected packages: vncorenlp\n","Successfully installed vncorenlp-1.0.3\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/22/aff234f4a841f8999e68a7a94bdd4b60b4cebcfeca5d67d61cd08c9179de/transformers-3.3.1-py3-none-any.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 5.0MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Collecting tokenizers==0.8.1.rc2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 29.7MB/s \n","\u001b[?25hCollecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 42.2MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 51.7MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=76b873d89932ba719513b04f21b4332f66cd2654930c9cf46d7c0ee79eb9afc2\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.3.1\n","Collecting fastBPE\n","  Downloading https://files.pythonhosted.org/packages/e1/37/f97181428a5d151501b90b2cebedf97c81b034ace753606a3cda5ad4e6e2/fastBPE-0.1.0.tar.gz\n","Building wheels for collected packages: fastBPE\n","  Building wheel for fastBPE (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fastBPE: filename=fastBPE-0.1.0-cp36-cp36m-linux_x86_64.whl size=481490 sha256=a13827f3ea53a24303aee040fe852a2246481398e40b1bd8701ff3ec98121a60\n","  Stored in directory: /root/.cache/pip/wheels/f3/0c/9c/fc62058b4d473a5602bcd3d3edfece796f123875379ea82d79\n","Successfully built fastBPE\n","Installing collected packages: fastBPE\n","Successfully installed fastBPE-0.1.0\n","Collecting keras-radam\n","  Downloading https://files.pythonhosted.org/packages/46/8d/b83ccaa94253fbc920b21981f038393041d92236bb541751b98a66a2ac1d/keras-radam-0.15.0.tar.gz\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-radam) (1.18.5)\n","Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-radam) (2.4.3)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-radam) (2.10.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-radam) (3.13)\n","Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-radam) (1.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras->keras-radam) (1.15.0)\n","Building wheels for collected packages: keras-radam\n","  Building wheel for keras-radam (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for keras-radam: filename=keras_radam-0.15.0-cp36-none-any.whl size=14686 sha256=01fe1f38e0fef43a18e9e3bcbc0fcd6f4a950ea902bbcf2e807e11e5aaadcc5e\n","  Stored in directory: /root/.cache/pip/wheels/79/a0/c0/670b0a118e8f078539fafec7bd02eba0af921f745660c7f83f\n","Successfully built keras-radam\n","Installing collected packages: keras-radam\n","Successfully installed keras-radam-0.15.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"S4nQTLEgyndZ","executionInfo":{"status":"ok","timestamp":1603012544459,"user_tz":-420,"elapsed":62598,"user":{"displayName":"Quốc Thái Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC0wF12OCloSJHbsb4W3DURco7tHfZ9TucBmircA=s64","userId":"10260876001198750079"}}},"source":["import pandas as pd, numpy as np\n","import tensorflow as tf\n","import tensorflow.keras.backend as K\n","from sklearn.model_selection import StratifiedKFold\n","from transformers import *"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"efm_WLimZWBx","executionInfo":{"status":"ok","timestamp":1603012553302,"user_tz":-420,"elapsed":71251,"user":{"displayName":"Quốc Thái Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC0wF12OCloSJHbsb4W3DURco7tHfZ9TucBmircA=s64","userId":"10260876001198750079"}},"outputId":"c62cce81-7abe-48e2-a37d-ad1fe4e49003","colab":{"base_uri":"https://localhost:8080/","height":301}},"source":["!wget https://public.vinai.io/PhoBERT_base_transformers.tar.gz\n","!tar -xzvf PhoBERT_base_transformers.tar.gz"],"execution_count":5,"outputs":[{"output_type":"stream","text":["--2020-10-18 09:15:45--  https://public.vinai.io/PhoBERT_base_transformers.tar.gz\n","Resolving public.vinai.io (public.vinai.io)... 99.86.38.27, 99.86.38.111, 99.86.38.8, ...\n","Connecting to public.vinai.io (public.vinai.io)|99.86.38.27|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 322405979 (307M) [application/x-tar]\n","Saving to: ‘PhoBERT_base_transformers.tar.gz’\n","\n","PhoBERT_base_transf 100%[===================>] 307.47M   241MB/s    in 1.3s    \n","\n","2020-10-18 09:15:47 (241 MB/s) - ‘PhoBERT_base_transformers.tar.gz’ saved [322405979/322405979]\n","\n","PhoBERT_base_transformers/\n","PhoBERT_base_transformers/config.json\n","PhoBERT_base_transformers/bpe.codes\n","PhoBERT_base_transformers/model.bin\n","PhoBERT_base_transformers/dict.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Y9FJqyck4cOE","executionInfo":{"status":"ok","timestamp":1603012553304,"user_tz":-420,"elapsed":71108,"user":{"displayName":"Quốc Thái Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC0wF12OCloSJHbsb4W3DURco7tHfZ9TucBmircA=s64","userId":"10260876001198750079"}}},"source":["phoBERT = 'PhoBERT_base_transformers'"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"ICFPBSMBcY4x","executionInfo":{"status":"ok","timestamp":1603012555154,"user_tz":-420,"elapsed":72802,"user":{"displayName":"Quốc Thái Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC0wF12OCloSJHbsb4W3DURco7tHfZ9TucBmircA=s64","userId":"10260876001198750079"}}},"source":["import pickle\n","import pandas as pd\n","df = pd.read_csv(path+\"VLSP2018/review_train.csv\")\n","df_dev = pd.read_csv(path+'VLSP2018/review_dev.csv')\n","df_test = pd.read_csv(path+'VLSP2018/review_test.csv')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"G59ynozm0Cfn","executionInfo":{"status":"ok","timestamp":1603012556122,"user_tz":-420,"elapsed":73610,"user":{"displayName":"Quốc Thái Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC0wF12OCloSJHbsb4W3DURco7tHfZ9TucBmircA=s64","userId":"10260876001198750079"}}},"source":["data_train = df.review.to_list()\n","label_train = pickle.load(open(path+'VLSP2018/aspect_train.pkl','rb'))\n","data_dev = df_dev.review.tolist()\n","label_dev =  pickle.load(open(path+'VLSP2018/aspect_dev.pkl','rb'))\n","data_test = df_test.review.tolist()\n","label_test = pickle.load(open(path+'VLSP2018/aspect_test.pkl','rb'))"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"W-gmSPcW0D4o","executionInfo":{"status":"ok","timestamp":1603012556128,"user_tz":-420,"elapsed":73453,"user":{"displayName":"Quốc Thái Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC0wF12OCloSJHbsb4W3DURco7tHfZ9TucBmircA=s64","userId":"10260876001198750079"}}},"source":["from fairseq.data.encoders.fastbpe import fastBPE\n","from fairseq.data import Dictionary\n","class BPE():\n","  bpe_codes = 'PhoBERT_base_transformers/bpe.codes'\n","\n","args = BPE()\n","bpe = fastBPE(args)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZEx5Lr822MP8","executionInfo":{"status":"ok","timestamp":1603012556129,"user_tz":-420,"elapsed":73257,"user":{"displayName":"Quốc Thái Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC0wF12OCloSJHbsb4W3DURco7tHfZ9TucBmircA=s64","userId":"10260876001198750079"}}},"source":["vocab = Dictionary()\n","vocab.add_from_file('PhoBERT_base_transformers/dict.txt')"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"QDY4E6Xd2flv","executionInfo":{"status":"ok","timestamp":1603012556131,"user_tz":-420,"elapsed":73104,"user":{"displayName":"Quốc Thái Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC0wF12OCloSJHbsb4W3DURco7tHfZ9TucBmircA=s64","userId":"10260876001198750079"}}},"source":["import numpy as np\n","from tqdm import tqdm\n","max_sequence_length = 256\n","def convert_lines(lines, vocab, bpe):\n","  '''\n","  lines: list các văn bản input\n","  vocab: từ điển dùng để encoding subwords\n","  bpe: \n","  '''\n","  # Khởi tạo ma trận output\n","  outputs = np.zeros((len(lines), max_sequence_length), dtype=np.int32) # --> shape (number_lines, max_seq_len)\n","  mask_token = np.zeros((len(lines), max_sequence_length), dtype=np.int32)\n","  # Index của các token cls (đầu câu), eos (cuối câu), padding (padding token)\n","  cls_id = 0\n","  eos_id = 2\n","  pad_id = 1\n","\n","  for idx, row in tqdm(enumerate(lines), total=len(lines)): \n","    # Mã hóa subwords theo byte pair encoding(bpe)\n","    subwords = bpe.encode('<s> '+ row +' </s>')\n","    input_ids = vocab.encode_line(subwords, append_eos=False, add_if_not_exist=False).long().tolist()\n","    # Truncate input nếu độ dài vượt quá max_seq_len\n","    if len(input_ids) > max_sequence_length: \n","      input_ids = input_ids[:max_sequence_length] \n","      input_ids[-1] = eos_id\n","    else:\n","      # Padding nếu độ dài câu chưa bằng max_seq_len\n","      input_ids = input_ids + [pad_id, ]*(max_sequence_length - len(input_ids))\n","      mask = [0 if i==1 else 1 for i in input_ids]\n","    outputs[idx,:] = np.array(input_ids)\n","    mask_token[idx,:] = np.array(mask)\n","  return outputs, mask_token"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bkhjrf5n2hQS","executionInfo":{"status":"ok","timestamp":1603012559631,"user_tz":-420,"elapsed":73940,"user":{"displayName":"Quốc Thái Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC0wF12OCloSJHbsb4W3DURco7tHfZ9TucBmircA=s64","userId":"10260876001198750079"}},"outputId":"9ea880d1-d052-41c2-d576-aa7dcda5222b","colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["X_train, X_train_mask = convert_lines(data_train, vocab, bpe)\n","X_dev, X_dev_mask = convert_lines(data_dev, vocab, bpe)\n","X_test, X_test_mask = convert_lines(data_test, vocab, bpe)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["100%|██████████| 2961/2961 [00:01<00:00, 1573.43it/s]\n","100%|██████████| 1290/1290 [00:00<00:00, 1652.76it/s]\n","100%|██████████| 500/500 [00:00<00:00, 707.20it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"sGHrsCLN6M8G","executionInfo":{"status":"ok","timestamp":1603012559633,"user_tz":-420,"elapsed":73733,"user":{"displayName":"Quốc Thái Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC0wF12OCloSJHbsb4W3DURco7tHfZ9TucBmircA=s64","userId":"10260876001198750079"}}},"source":["y_train = np.array(label_train).astype('float32')\n","y_dev = np.array(label_dev).astype('float32')\n","y_test = np.array(label_test).astype('float32')"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"jJ5pd3e2_YtS","executionInfo":{"status":"ok","timestamp":1603012559633,"user_tz":-420,"elapsed":73597,"user":{"displayName":"Quốc Thái Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC0wF12OCloSJHbsb4W3DURco7tHfZ9TucBmircA=s64","userId":"10260876001198750079"}}},"source":["from tensorflow.keras.layers import Dense, Input, Flatten,SpatialDropout1D,Bidirectional, BatchNormalization\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding, Concatenate, Dropout,GlobalMaxPool1D,Lambda,MaxPool1D\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Bidirectional,LSTM,GRU\n","from tensorflow.keras.optimizers import Adam\n","from keras_radam.training import RAdamOptimizer"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"E6Vbybk_o3cb","executionInfo":{"status":"ok","timestamp":1603012571389,"user_tz":-420,"elapsed":85155,"user":{"displayName":"Quốc Thái Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC0wF12OCloSJHbsb4W3DURco7tHfZ9TucBmircA=s64","userId":"10260876001198750079"}},"outputId":"d721dd3a-9f75-4f7e-8530-81ec6193e8b1","colab":{"base_uri":"https://localhost:8080/","height":126}},"source":["config = RobertaConfig.from_pretrained(\n","  phoBERT+'/config.json',\n","  output_hidden_states=True,\n","  num_labels=12\n","  )\n","model_bert = TFRobertaModel.from_pretrained(phoBERT+'/model.bin', config=config, from_pt=True)\n","\n","input_ids = Input(shape=(256,), name='input_token', dtype='int64')\n","input_mask = Input(shape=(256,), name='mask_token', dtype='int64')\n","\n","pretrain = model_bert(input_ids, attention_mask=input_mask)[0]\n","cls_token = pretrain[:,0,:]\n","dropout_layer = Dropout(0.2)(cls_token)\n","\n","dense_layer = Dense(768, activation='relu')(dropout_layer)\n","dense_layer = Dense(512, activation='relu')(dense_layer)\n","dense_layer = Dense(256, activation='relu')(dense_layer)\n","preds = Dense(12, activation='sigmoid')(dense_layer)\n","\n","model = Model([input_ids,input_mask], preds)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']\n","- This IS expected if you are initializing TFRobertaModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPretraining model).\n","- This IS NOT expected if you are initializing TFRobertaModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFRobertaModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"sLwtGcC2zjnm","executionInfo":{"status":"ok","timestamp":1603012571390,"user_tz":-420,"elapsed":84935,"user":{"displayName":"Quốc Thái Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC0wF12OCloSJHbsb4W3DURco7tHfZ9TucBmircA=s64","userId":"10260876001198750079"}}},"source":["def f1(y_true, y_pred):\n","    y_true = K.flatten(y_true)\n","    y_pred = K.flatten(y_pred)\n","    return 2 * (K.sum(y_true * y_pred)+ K.epsilon()) / (K.sum(y_true) + K.sum(y_pred) + K.epsilon())"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"NgJ5U5ii1Btn","executionInfo":{"status":"ok","timestamp":1603012599361,"user_tz":-420,"elapsed":1088,"user":{"displayName":"Quốc Thái Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC0wF12OCloSJHbsb4W3DURco7tHfZ9TucBmircA=s64","userId":"10260876001198750079"}}},"source":["LR = 2e-5\n","EPOCHS = 10\n","BATCH_SIZE = 16"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"vflspJ8giimQ","executionInfo":{"status":"ok","timestamp":1603012572472,"user_tz":-420,"elapsed":1068,"user":{"displayName":"Quốc Thái Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC0wF12OCloSJHbsb4W3DURco7tHfZ9TucBmircA=s64","userId":"10260876001198750079"}}},"source":["import tensorflow_addons as tfa\n","optimizer = tfa.optimizers.RectifiedAdam(lr=LR)\n","loss = tfa.losses.SigmoidFocalCrossEntropy()"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"OI_dL3vosXRx","executionInfo":{"status":"ok","timestamp":1603012600405,"user_tz":-420,"elapsed":567,"user":{"displayName":"Quốc Thái Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC0wF12OCloSJHbsb4W3DURco7tHfZ9TucBmircA=s64","userId":"10260876001198750079"}}},"source":["model.compile(loss='binary_crossentropy',\n","              optimizer=Adam(learning_rate=LR),\n","              metrics=[f1])"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"3TwqXSfDrzPl"},"source":["checkpoint = tf.keras.callbacks.ModelCheckpoint(path+'phoBERT_checkpoint.h5', monitor='val_f1', verbose=1, save_best_only=True, mode='max')\n","callback_list = [checkpoint]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZH0FvGDisWRK","executionInfo":{"status":"ok","timestamp":1603014307026,"user_tz":-420,"elapsed":1706083,"user":{"displayName":"Quốc Thái Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC0wF12OCloSJHbsb4W3DURco7tHfZ9TucBmircA=s64","userId":"10260876001198750079"}},"outputId":"e1139089-700e-482a-800e-3e38d770f2cc","colab":{"base_uri":"https://localhost:8080/","height":481}},"source":["model.fit([X_train, X_train_mask], y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose = 1, validation_data=([X_test, X_test_mask], y_test))     "],"execution_count":23,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n","WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n","186/186 [==============================] - 170s 916ms/step - loss: 0.3794 - f1: 0.5397 - val_loss: 0.5182 - val_f1: 0.6009\n","Epoch 2/10\n","186/186 [==============================] - 168s 904ms/step - loss: 0.3104 - f1: 0.6201 - val_loss: 0.5471 - val_f1: 0.5420\n","Epoch 3/10\n","186/186 [==============================] - 168s 903ms/step - loss: 0.2668 - f1: 0.6733 - val_loss: 0.4220 - val_f1: 0.6459\n","Epoch 4/10\n","186/186 [==============================] - 168s 904ms/step - loss: 0.2288 - f1: 0.7203 - val_loss: 0.3816 - val_f1: 0.7004\n","Epoch 5/10\n","186/186 [==============================] - 168s 903ms/step - loss: 0.1968 - f1: 0.7569 - val_loss: 0.3847 - val_f1: 0.7196\n","Epoch 6/10\n","186/186 [==============================] - 168s 903ms/step - loss: 0.1789 - f1: 0.7814 - val_loss: 0.3994 - val_f1: 0.7410\n","Epoch 7/10\n","186/186 [==============================] - 168s 903ms/step - loss: 0.1532 - f1: 0.8117 - val_loss: 0.3865 - val_f1: 0.7374\n","Epoch 8/10\n","186/186 [==============================] - 168s 903ms/step - loss: 0.1326 - f1: 0.8320 - val_loss: 0.4064 - val_f1: 0.7611\n","Epoch 9/10\n","186/186 [==============================] - 168s 903ms/step - loss: 0.1168 - f1: 0.8550 - val_loss: 0.4227 - val_f1: 0.7306\n","Epoch 10/10\n","186/186 [==============================] - 168s 903ms/step - loss: 0.0961 - f1: 0.8783 - val_loss: 0.4697 - val_f1: 0.7359\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f58da07ae80>"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"fdRvu2CZQcGY","executionInfo":{"status":"ok","timestamp":1603015998040,"user_tz":-420,"elapsed":3395779,"user":{"displayName":"Quốc Thái Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC0wF12OCloSJHbsb4W3DURco7tHfZ9TucBmircA=s64","userId":"10260876001198750079"}},"outputId":"50ed2201-d5c0-42ff-fc83-eae3234b0c30","colab":{"base_uri":"https://localhost:8080/","height":390}},"source":["model.fit([X_train, X_train_mask], y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose = 1, validation_data=([X_test, X_test_mask], y_test))     "],"execution_count":24,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","186/186 [==============================] - 168s 904ms/step - loss: 0.0850 - f1: 0.8924 - val_loss: 0.4608 - val_f1: 0.7560\n","Epoch 2/10\n","186/186 [==============================] - 168s 903ms/step - loss: 0.0679 - f1: 0.9126 - val_loss: 0.4773 - val_f1: 0.7722\n","Epoch 3/10\n","186/186 [==============================] - 168s 904ms/step - loss: 0.0569 - f1: 0.9228 - val_loss: 0.4973 - val_f1: 0.7705\n","Epoch 4/10\n","186/186 [==============================] - 168s 904ms/step - loss: 0.0442 - f1: 0.9409 - val_loss: 0.5402 - val_f1: 0.7897\n","Epoch 5/10\n","186/186 [==============================] - 168s 903ms/step - loss: 0.0379 - f1: 0.9475 - val_loss: 0.4927 - val_f1: 0.7819\n","Epoch 6/10\n","186/186 [==============================] - 168s 904ms/step - loss: 0.0368 - f1: 0.9516 - val_loss: 0.5564 - val_f1: 0.7851\n","Epoch 7/10\n","186/186 [==============================] - 168s 903ms/step - loss: 0.0290 - f1: 0.9610 - val_loss: 0.5640 - val_f1: 0.7819\n","Epoch 8/10\n","186/186 [==============================] - 168s 903ms/step - loss: 0.0252 - f1: 0.9657 - val_loss: 0.5965 - val_f1: 0.7917\n","Epoch 9/10\n","186/186 [==============================] - 168s 904ms/step - loss: 0.0197 - f1: 0.9720 - val_loss: 0.6371 - val_f1: 0.7890\n","Epoch 10/10\n","186/186 [==============================] - 168s 902ms/step - loss: 0.0178 - f1: 0.9751 - val_loss: 0.7075 - val_f1: 0.7695\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f56cc34b4e0>"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"ZOpl31Yp2KD2","executionInfo":{"status":"ok","timestamp":1603017686171,"user_tz":-420,"elapsed":5083300,"user":{"displayName":"Quốc Thái Nguyễn","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiC0wF12OCloSJHbsb4W3DURco7tHfZ9TucBmircA=s64","userId":"10260876001198750079"}},"outputId":"f9574c1a-cfe8-49c0-a3df-ec99d6b4f8a8","colab":{"base_uri":"https://localhost:8080/","height":390}},"source":["model.fit([X_train, X_train_mask], y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose = 1, validation_data=([X_test, X_test_mask], y_test))     "],"execution_count":25,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","186/186 [==============================] - 168s 903ms/step - loss: 0.0167 - f1: 0.9772 - val_loss: 0.7220 - val_f1: 0.7782\n","Epoch 2/10\n","186/186 [==============================] - 168s 903ms/step - loss: 0.0147 - f1: 0.9792 - val_loss: 0.6777 - val_f1: 0.7862\n","Epoch 3/10\n","186/186 [==============================] - 168s 903ms/step - loss: 0.0142 - f1: 0.9804 - val_loss: 0.6972 - val_f1: 0.7885\n","Epoch 4/10\n","186/186 [==============================] - 168s 904ms/step - loss: 0.0144 - f1: 0.9803 - val_loss: 0.7071 - val_f1: 0.7990\n","Epoch 5/10\n","186/186 [==============================] - 168s 904ms/step - loss: 0.0136 - f1: 0.9820 - val_loss: 0.7848 - val_f1: 0.7957\n","Epoch 6/10\n","186/186 [==============================] - 168s 904ms/step - loss: 0.0093 - f1: 0.9866 - val_loss: 0.7924 - val_f1: 0.7941\n","Epoch 7/10\n","186/186 [==============================] - 168s 905ms/step - loss: 0.0087 - f1: 0.9877 - val_loss: 0.7746 - val_f1: 0.7970\n","Epoch 8/10\n","186/186 [==============================] - 168s 904ms/step - loss: 0.0095 - f1: 0.9872 - val_loss: 0.8049 - val_f1: 0.7894\n","Epoch 9/10\n","186/186 [==============================] - 168s 903ms/step - loss: 0.0125 - f1: 0.9850 - val_loss: 0.8377 - val_f1: 0.7908\n","Epoch 10/10\n","186/186 [==============================] - 168s 904ms/step - loss: 0.0110 - f1: 0.9866 - val_loss: 0.8571 - val_f1: 0.7943\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f56cc34b278>"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"F-uhbgMdS6_4","outputId":"c0e9a9c2-0561-4686-bb64-fb35a7c2fa5c","colab":{"base_uri":"https://localhost:8080/","height":159}},"source":["model.fit([X_train, X_train_mask], y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose = 1, validation_data=([X_test, X_test_mask], y_test))     "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","186/186 [==============================] - 168s 903ms/step - loss: 0.0084 - f1: 0.9889 - val_loss: 0.8157 - val_f1: 0.8153\n","Epoch 2/10\n","186/186 [==============================] - 168s 903ms/step - loss: 0.0059 - f1: 0.9915 - val_loss: 0.8966 - val_f1: 0.7959\n","Epoch 3/10\n","186/186 [==============================] - 168s 902ms/step - loss: 0.0049 - f1: 0.9928 - val_loss: 0.9048 - val_f1: 0.7907\n","Epoch 4/10\n"," 30/186 [===>..........................] - ETA: 2:10 - loss: 0.0075 - f1: 0.9904"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QHqBYM7xvfgL"},"source":["model.save_weights(path+'phobert_checkpoint.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TC26KlDzFDZb"},"source":["model.load_weights(path+'phobert_checkpoint.h5')"],"execution_count":null,"outputs":[]}]}